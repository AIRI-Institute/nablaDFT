{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3905936-bf37-4f3e-aa85-1ec1c0dfe16b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Train/test cycles example using PaiNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e852be1-9e60-414b-a13b-de9b96870fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on https://github.com/atomistic-machine-learning/schnetpack/blob/master/examples/tutorials/tutorial_02_qm9.ipynb\n",
    "import os\n",
    "import tqdm\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint\n",
    "\n",
    "import schnetpack as spk\n",
    "import schnetpack.representation as rep\n",
    "import schnetpack.task as task\n",
    "import schnetpack.transform as trn\n",
    "\n",
    "import torch\n",
    "import torchmetrics\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "from nablaDFT.dataset import NablaDFT\n",
    "from nablaDFT.painn.train_painn import AtomisticTaskFixed, seed_everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d6f8759",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'dataset_train_2k'  # Name of the training dataset\n",
    "datapath = 'database'              # Path to the selected dataset\n",
    "logspath = 'logs'                  # Path to log files\n",
    "nepochs = 200                        # Number of epochs to train for\n",
    "seed = 1799                        # Random seed number for reproducibility\n",
    "batch_size = 100                   # Size of each batch for training\n",
    "n_interactions = 6                 # Number of interactions to consider between atoms\n",
    "n_atom_basis = 128                 # Number of basis functions for atoms in the representation\n",
    "n_rbf = 20                         # Number of radial basis functions in the representation\n",
    "cutoff = 5.0                       # Cutoff distance (in Bohr) for computing interactions\n",
    "devices = 1                        # Number of GPU/TPU/CPU devices to use for training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9dda503-3240-4538-b7da-afcf91ff4c56",
   "metadata": {},
   "source": [
    "## Downloading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c047086",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(seed)\n",
    "workpath = logspath\n",
    "\n",
    "if not os.path.exists(workpath):\n",
    "    os.makedirs(workpath)\n",
    "\n",
    "data = NablaDFT(\n",
    "    \"ASE\",\n",
    "    dataset_name,\n",
    "    datapath=datapath,\n",
    "    data_workdir=workpath,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=4,\n",
    "    transforms=[\n",
    "        trn.ASENeighborList(cutoff=cutoff),\n",
    "        trn.RemoveOffsets(\"energy\", remove_mean=True, remove_atomrefs=False),\n",
    "        trn.CastTo32(),\n",
    "    ],\n",
    "    split_file=os.path.join(workpath, \"split.npz\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccae870c-b44c-46f1-9d6d-9c9a7940f6a1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Initializing training procedure and starting training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9a2371",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairwise_distance = spk.atomistic.PairwiseDistances()\n",
    "radial_basis = spk.nn.radial.GaussianRBF(\n",
    "    n_rbf=n_rbf,\n",
    "    cutoff=cutoff\n",
    ")\n",
    "cutoff_fn = spk.nn.cutoff.CosineCutoff(cutoff)\n",
    "representation = rep.PaiNN(\n",
    "    n_interactions=n_interactions,\n",
    "    n_atom_basis=n_atom_basis,\n",
    "    radial_basis=radial_basis,\n",
    "    cutoff_fn=cutoff_fn\n",
    ")\n",
    "pred_energy = spk.atomistic.Atomwise(\n",
    "    n_in=representation.n_atom_basis,\n",
    "    output_key=\"energy\"\n",
    ")\n",
    "postprocessors = [\n",
    "    trn.CastTo64(),\n",
    "    trn.AddOffsets(\"energy\", add_mean=True)\n",
    "]\n",
    "nnpot = spk.model.NeuralNetworkPotential(\n",
    "    representation=representation,\n",
    "    input_modules=[pairwise_distance],\n",
    "    output_modules=[pred_energy],\n",
    "    postprocessors=postprocessors\n",
    ")\n",
    "output_energy = spk.task.ModelOutput(\n",
    "    name=\"energy\",\n",
    "    loss_fn=torch.nn.MSELoss(),\n",
    "    loss_weight=1,\n",
    "    metrics={\"MAE\": torchmetrics.MeanAbsoluteError()}\n",
    ")\n",
    "\n",
    "scheduler_args = {\n",
    "    \"factor\": 0.8,\n",
    "    \"patience\": 10,\n",
    "    \"min_lr\": 1e-06\n",
    "}\n",
    "\n",
    "task = spk.task.AtomisticTask(\n",
    "    model=nnpot,\n",
    "    outputs=[output_energy],\n",
    "    optimizer_cls=torch.optim.AdamW,\n",
    "    optimizer_args={\"lr\": 1e-4},\n",
    "    scheduler_cls=ReduceLROnPlateau,\n",
    "    scheduler_args=scheduler_args,\n",
    "    scheduler_monitor=\"val_loss\"\n",
    ")\n",
    "\n",
    "# create trainer\n",
    "logger = pl.loggers.TensorBoardLogger(save_dir=workpath)\n",
    "callbacks = [\n",
    "    spk.train.ModelCheckpoint(\n",
    "        model_path=os.path.join(workpath, \"best_inference_model\"),\n",
    "        save_top_k=1,\n",
    "        monitor=\"val_loss\"\n",
    "    )\n",
    "]\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    accelerator='gpu',\n",
    "    devices=devices,\n",
    "    callbacks=callbacks,\n",
    "    logger=logger,\n",
    "    default_root_dir=workpath,\n",
    "    max_epochs=nepochs,\n",
    ")\n",
    "\n",
    "lr_monitor = LearningRateMonitor(logging_interval='step')\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    save_top_k=1,\n",
    "    monitor=\"step\",\n",
    "    mode=\"max\",\n",
    "    filename=\"last-chkpt-{epoch:02d}-{global_step}\",\n",
    ")\n",
    "callbacks = [\n",
    "    spk.train.ModelCheckpoint(\n",
    "        model_path=os.path.join(workpath, \"best_inference_model\"),\n",
    "        save_top_k=1,\n",
    "        monitor=\"val_loss\"\n",
    "    ),\n",
    "    lr_monitor,\n",
    "    checkpoint_callback\n",
    "]\n",
    "\n",
    "trainer.fit(task, datamodule=data.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09e7685-804a-404d-a7c4-b7aad039c490",
   "metadata": {},
   "source": [
    "## Initializing the testing procedure and computing the metric's result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd6d64ff-541c-4b26-8cca-cd80e4287ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 18/18 [00:10<00:00,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7281)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset_name_test = 'dataset_test_conformations_2k'\n",
    "datapath = 'database_test'\n",
    "batch_size = 100\n",
    "cutoff = 5.0\n",
    "gpu = 0\n",
    "\n",
    "if gpu == -1:\n",
    "    device = torch.device(\"cpu\")\n",
    "else:\n",
    "    device = torch.cuda.device(gpu)\n",
    "\n",
    "data_test = NablaDFT(\n",
    "    \"ASE\",\n",
    "    dataset_name_test,\n",
    "    datapath=datapath,\n",
    "    data_workdir=workpath,\n",
    "    distance_unit=\"Bohr\",\n",
    "    batch_size=batch_size,\n",
    "    train_ratio=0,\n",
    "    num_workers=1,\n",
    "    transforms=[\n",
    "        trn.ASENeighborList(cutoff=cutoff),\n",
    "        trn.CastTo32()\n",
    "    ],\n",
    "    split_file=os.path.join(workpath, \"split_test.npz\")\n",
    ")\n",
    "\n",
    "data_test.dataset.prepare_data()\n",
    "data_test.dataset.setup()\n",
    "\n",
    "best_model = torch.load(os.path.join(workpath, 'best_inference_model'))\n",
    "best_model = best_model.cuda()\n",
    "best_model = best_model.eval()\n",
    "\n",
    "metric = torchmetrics.MeanAbsoluteError()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x in tqdm.tqdm(data_test.dataset.val_dataloader()):\n",
    "        for k in x:\n",
    "            if x[k].dtype == torch.float64:\n",
    "                x[k] = x[k].float()\n",
    "            x[k] = x[k].to(device)\n",
    "\n",
    "        target = x['energy'].cpu().clone()\n",
    "        prediction = best_model(x)['energy'].cpu()\n",
    "        mae = metric(prediction, target)\n",
    "\n",
    "print(metric.compute())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e09a684-74d2-4d7d-bd64-2bbcfdfceb86",
   "metadata": {},
   "source": [
    "## Downloading dataset with atomic energies subtracted and starting the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bbbedf-4781-4a19-a21c-94bcb54e1d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "logspath = 'logs_remove_atomrefs'\n",
    "workpath = logspath\n",
    "data_remove_atomrefs = NablaDFT(\"ASE\", dataset_name,\n",
    "                datapath=datapath,\n",
    "                data_workdir=workpath,\n",
    "                batch_size=batch_size,\n",
    "                num_workers=4,\n",
    "                transforms=[\n",
    "                            trn.ASENeighborList(cutoff=cutoff),\n",
    "                            trn.RemoveOffsets(\"energy\", remove_mean=True, remove_atomrefs=True),\n",
    "                            trn.CastTo32()\n",
    "                           ],\n",
    "                split_file=os.path.join(workpath, \"split.npz\"))\n",
    "\n",
    "pairwise_distance = spk.atomistic.PairwiseDistances()\n",
    "radial_basis = spk.nn.radial.GaussianRBF(\n",
    "    n_rbf=n_rbf,\n",
    "    cutoff=cutoff\n",
    ")\n",
    "cutoff_fn = spk.nn.cutoff.CosineCutoff(cutoff)\n",
    "representation = rep.PaiNN(\n",
    "    n_interactions=n_interactions,\n",
    "    n_atom_basis=n_atom_basis,\n",
    "    radial_basis=radial_basis,\n",
    "    cutoff_fn=cutoff_fn\n",
    ")\n",
    "pred_energy = spk.atomistic.Atomwise(\n",
    "    n_in=representation.n_atom_basis,\n",
    "    output_key=\"energy\"\n",
    ")\n",
    "postprocessors = [\n",
    "    trn.CastTo64(),\n",
    "    trn.AddOffsets(\"energy\", add_mean=True,\n",
    "    add_atomrefs=True)\n",
    "]\n",
    "nnpot = spk.model.NeuralNetworkPotential(\n",
    "    representation=representation,\n",
    "    input_modules=[pairwise_distance],\n",
    "    output_modules=[pred_energy],\n",
    "    postprocessors=postprocessors\n",
    ")\n",
    "output_energy = spk.task.ModelOutput(\n",
    "    name=\"energy\",\n",
    "    loss_fn=torch.nn.MSELoss(),\n",
    "    loss_weight=1,\n",
    "    metrics={\"MAE\": torchmetrics.MeanAbsoluteError()}\n",
    ")\n",
    "\n",
    "scheduler_args = {\n",
    "    \"factor\": 0.8,\n",
    "    \"patience\": 10,\n",
    "    \"min_lr\": 1e-06\n",
    "}\n",
    "\n",
    "task = spk.task.AtomisticTask(\n",
    "    model=nnpot,\n",
    "    outputs=[output_energy],\n",
    "    optimizer_cls=torch.optim.AdamW,\n",
    "    optimizer_args={\"lr\": 1e-4},\n",
    "    scheduler_cls=ReduceLROnPlateau,\n",
    "    scheduler_args=scheduler_args,\n",
    "    scheduler_monitor=\"val_loss\"\n",
    ")\n",
    "\n",
    "# create trainer\n",
    "logger = pl.loggers.TensorBoardLogger(save_dir=workpath)\n",
    "callbacks = [\n",
    "    spk.train.ModelCheckpoint(\n",
    "        model_path=os.path.join(workpath, \"best_inference_model\"),\n",
    "        save_top_k=1,\n",
    "        monitor=\"val_loss\"\n",
    "    )\n",
    "]\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    accelerator='gpu',\n",
    "    devices=devices,\n",
    "    callbacks=callbacks,\n",
    "    logger=logger,\n",
    "    default_root_dir=workpath,\n",
    "    max_epochs=nepochs,\n",
    ")\n",
    "\n",
    "lr_monitor = LearningRateMonitor(logging_interval='step')\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    save_top_k=1,\n",
    "    monitor=\"step\",\n",
    "    mode=\"max\",\n",
    "    filename=\"last-chkpt-{epoch:02d}-{global_step}\",\n",
    ")\n",
    "callbacks = [\n",
    "    spk.train.ModelCheckpoint(\n",
    "        model_path=os.path.join(workpath, \"best_inference_model\"),\n",
    "        save_top_k=1,\n",
    "        monitor=\"val_loss\"\n",
    "    ),\n",
    "    lr_monitor,\n",
    "    checkpoint_callback\n",
    "]\n",
    "\n",
    "trainer.fit(task, datamodule=data_remove_atomrefs.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5d182b-ff2a-4a10-8e19-9d1093a5e250",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 18/18 [00:10<00:00,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0132)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "datapath = 'database_test'\n",
    "batch_size = 100\n",
    "cutoff = 5.0\n",
    "gpu = 0\n",
    "\n",
    "if gpu == -1:\n",
    "    device = torch.device(\"cpu\")\n",
    "else:\n",
    "    device = torch.cuda.device(gpu)\n",
    "\n",
    "data_remove_atomrefs_test = NablaDFT(\n",
    "    \"ASE\",\n",
    "    dataset_name_test,\n",
    "    datapath=datapath,\n",
    "    data_workdir=workpath,\n",
    "    distance_unit=\"Bohr\",\n",
    "    batch_size=batch_size,\n",
    "    train_ratio=0,\n",
    "    num_workers=1,\n",
    "    transforms=[\n",
    "        trn.ASENeighborList(cutoff=cutoff),\n",
    "        trn.CastTo32()\n",
    "    ],\n",
    "    split_file=os.path.join(workpath, \"split_test.npz\")\n",
    ")\n",
    "\n",
    "data_remove_atomrefs_test.dataset.prepare_data()\n",
    "data_remove_atomrefs_test.dataset.setup()\n",
    "\n",
    "best_model = torch.load(os.path.join(workpath, 'best_inference_model'))\n",
    "best_model = best_model.cuda()\n",
    "best_model = best_model.eval()\n",
    "\n",
    "metric = torchmetrics.MeanAbsoluteError()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x in tqdm.tqdm(data_remove_atomrefs_test.dataset.val_dataloader()):\n",
    "        for k in x:\n",
    "            if x[k].dtype == torch.float64:\n",
    "                x[k] = x[k].float()\n",
    "            x[k] = x[k].to(device)\n",
    "\n",
    "        target = x['energy'].cpu().clone()\n",
    "        prediction = best_model(x)['energy'].cpu()\n",
    "        mae = metric(prediction, target)\n",
    "\n",
    "print(metric.compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4909ddb-4ba6-45c2-8f00-e45df74b2579",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
